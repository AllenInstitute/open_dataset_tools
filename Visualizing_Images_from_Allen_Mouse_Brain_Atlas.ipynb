{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of the data and metadata for the Allen Mouse Brain Atlas is now stored in a public bucket in Amazon's S3 data storage service. The utilities demonstrated here access that bucket through AWS's `boto3` API. In order to access the bucket, you will need an AWS account with credentials stored in a csv file that looks like\n",
    "```\n",
    "column1,Access key ID,Secret access key,column4,column5...\n",
    "data1,your_access_key_id,your_secret_access_key,data4,data5,...\n",
    "```\n",
    "The utilities in this module will use the credentials stored in that file to create a `boto3.Session` which will handle all transactions with S3.\n",
    "\n",
    "We create that `Session` below, using the credentials in the file `accessKeys.csv`. This file is not a part of the repo you have cloned. It is a part of the developer's local system. You must provide your own equivalent of `accessKeys.csv` and alter the code below accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "credential_filename = 'accessKeys.csv'\n",
    "assert os.path.isfile(credential_filename)\n",
    "\n",
    "import aws_utils\n",
    "boto3_session = aws_utils.get_boto3_session(credential_filename)\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a `boto3.Session`, we will download the metadata for the Allen Mouse Brain Atlas. First, let's import the module containing the utilities for accessing the atlas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import aba_mouse_utils as mouse_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's download the metadata for the entire atlas. The method below downloads the file into a directory `tmp/` which is a subdirectory of this repository. If you want to use a different temporary directory, you can set it with the `tmp_dir` kwarg in that method (and all of the methods below that download data from S3). In addition to downloading the metadata, the method below will also load it into memory, giving you access to a list of dicts, each of which represents one \"section data set\" in the Allen Mouse Brain Atlas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atlas_metadata = mouse_utils.get_atlas_metadata(session=boto3_session)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider just the first two elements in `atlas_metadata`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atlas_metadata[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see the very high level metadata about each of the section data sets in the atlas. To download the detailed metadata about one of these sets, we use the class `SectionDatSet`, which we instantiate with the `id` of the section data set found in the atlas metadata above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "section_data = mouse_utils.SectionDataSet(5, session=boto3_session)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`section_data.metadata` is now a dict containing all of the metadata about the section data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_list = list(section_data.metadata.keys())\n",
    "key_list.sort()\n",
    "print(key_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(json.dumps(section_data.metadata, indent=2, sort_keys=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metadata about the images that make up this section dataset can be accessed according to either their `sub_image_id` or their `tissue_index`. Below, we show lists of valid values for these parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(section_data.tissue_indices)\n",
    "print('')\n",
    "print(section_data.sub_image_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the metadata associated with one of these images, use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_metadata = section_data.image_metadata_from_tissue_index(58)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(image_metadata['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt_metadata = section_data.image_metadata_from_sub_image(image_metadata['id'])\n",
    "assert alt_metadata == image_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(image_metadata.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of the images in the atlas exist at multiple resolutions. Each resolution is identified by a downsampling tier. `downsampling == 0` corresponds to the full resolution image. Each larger downsampling tier corresponds to a factor of 2 reduction in resolution in both the x and y direction, so `downsampling == 1` is a factor of 4 smaller than `downsampling == 0`; `downsampling == 2` is a factor of 16 smaller than `downsampling == 0`; etc.\n",
    "\n",
    "To see what downsampling tiers are available for each image, use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "downsampling_tiers = list(image_metadata['downsampling'].keys())\n",
    "downsampling_tiers.sort()\n",
    "print(downsampling_tiers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** in some rare cases, the full-resolution image file became corrupted during processing and was lost. These will correspond to images that have a valid `downsample_1` but no `downsample_0`. If you ever ask for a downsampling index that does not exist, the code should fail gracefully and issue a warning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The methods `SectionDataSet.download_image_from_tissue_index` and `SectionDataSet.download_image_from_sub_image` allow you to download an image as a TIFF file, specifying it by either its tissue index or its sub-image ID and its downsampling index.\n",
    "\n",
    "Let's download the `downsampling == 3` copy of the image with `tissue_index == 58`. We must specify a local filename in which to write the image.\n",
    "\n",
    "These methods return `True` if the image was downloaded; `False` otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_filename = 'example_aba_image.tiff'\n",
    "section_data.download_image_from_tissue_index(58, 3, local_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize the image with matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import PIL.Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,15))\n",
    "img = PIL.Image.open(local_filename)\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's backup and take a closer look at the metadata associated with this image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(json.dumps(image_metadata, indent=2, sort_keys=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each downsampling tier lists a `height`, a `width`, an `x` coordinate, and a `y` coordinate. `x` and `y` denote the upper left corner of the image. Naively, `height` and `width` denote the height and width of the TIFF file itself (that is why, in this case, they are identical to `image_file_height` and `image_file_width`). In some cases, however, one TIFF file can contain multiple images of tissues, in which case these parameters will denote the origin and bounds of individual sub images. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = mouse_utils.SectionDataSet(100055044, session=boto3_session)\n",
    "subimage_5 = dataset.image_metadata_from_tissue_index(5)\n",
    "subimage_13 = dataset.image_metadata_from_tissue_index(13)\n",
    "assert subimage_5['image_file_name'] == subimage_13['image_file_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(json.dumps(subimage_5, indent=2, sort_keys=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(json.dumps(subimage_13, indent=2, sort_keys=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the two sub-images share the same `image_file_name`, indicating that they are subsections of the same TIFF file. Similarly, for each downsampling tier, they share the same `image_file_height` and `image_file_width`, representing the total number of pixels in the TIFF file, but they have different `height`, `width`, `x`, and `y`, representing the different bounding boxes of the different sub-images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ds in subimage_5['downsampling'].keys():\n",
    "    assert subimage_5['downsampling'][ds]['image_file_height'] == subimage_13['downsampling'][ds]['image_file_height']\n",
    "    assert subimage_5['downsampling'][ds]['image_file_width'] == subimage_13['downsampling'][ds]['image_file_width']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's download and visualize the image file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_filename = 'example_compound_image.tiff'\n",
    "dataset.download_image_from_tissue_index(13, 5, local_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,15))\n",
    "img = PIL.Image.open(local_filename)\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
